\chapter{Marco metodológico}
\label{capitulo2}
\lhead{Capítulo 2. \emph{Marco metodológico}}

En este capítulo se detalla la representación utilizada para los cromosomas, la función objetivo, las adaptaciones particulares que se hizo a cada algoritmo evolutivo usado en el experimento, el proceso de validación cruzada, la técnica de estratificación. Además se presenta los conjuntos de datos usados para el experimento y se explica cómo es el experimento que se realizó a cabo.

\section{Representación del cromosoma}

Sea T el conjunto de instancias a reducir de tamaño \texttt{n}, la representación usada para modelar el problema de selección de prototipos es el de un mapa de bits de tamaño \texttt{n}, donde cada bit representa una instancia dentro de T; si el valor del bit i es 1, entonces la instancia $t_i \in T$ está en el conjunto reducido S, si el bit i es 0, $t_i$ se encuentra por fuera de S. En este sentido, el conjunto $S_M$, que representa el conjunto reducido S dado por el mapa de bits M, se define como en la ecuación (2.1). Además un ejemplo se presenta en \ref{representacion}.

\begin{equation}
S_m = \left\{ t_i \in T \mid i = 1 \dots n \land s_i = 1 \right\}
\end{equation} 

\begin{figure}[]
\centering
\includegraphics[height=3cm,width=10cm]{representacion.png}
\caption[Representacion]{Representación de un cromosoma y su respectivo conjunto reducido}
\label{representacion}
\end{figure}

\section{Función objetivo}

Se necesita una función con la cual los algoritmos evolutivos puedan evaluar cuán buena es una solución dada, además de que dicha función debe permitir establecer una relación de orden entre las soluciones con el fin de decidir cuál cromosoma es mejor que otro. Como se explicó anteriormente, los algoritmos evolutivos buscan aproximarse al óptimo global, que en este caso es el conjunto reducido S con menor cardinalidad posible y mayor precisión en la clasificación de instancias nuevas. Es por eso que se adopta una función objetivo derivada del trabajo de \emph{Cano, J.} en \cite{de2004reduccion}, la cual se presenta a continuación:

\begin{equation}
\mathcal{F}(S) = \alpha * error(S) + (1 - \alpha) *  \mid S \mid
\end{equation} 

Donde $\mathcal{F}: W \rightarrow \mathbb{R}$ es la función objetivo, S es el conjunto reducido a evaluar, W es el espacio de cromosomas asociados a los distintas posibilidades de conjuntos reducidos, $\alpha$ es un parámetro que controla cuánta importancia se le da al error asociado a S con respecto a la cardinalidad de S, $\mid S \mid$ es la cardinalidad del conjunto y error(S) es el porcentaje de error al clasificar un conjunto de prueba TS usando 1-KNN con S como conjunto de referencia. El $\alpha$ usado es 0.5 como lo establecen en \cite{de2004reduccion} para darle la misma importancia a la reducción de datos como a mantener bajo los porcentajes de error en la clasificación.

Dado esta función objetivo, la meta de todas las metaheurísticas implementandas se vuelve minimizar $\mathcal{F}(S)$, lo cual quiere decir que se busca tanto reducir $\mid S \mid$, como reducir error(S). Una conjunto $S_i$ es mejor que un conjunto $S_j$ si $\mathcal{F}(S_i) < \mathcal{F}(S_j)$.  

\section{Adaptaciones de los algoritmos evolutivos}

Para aplicar los distintos algoritmos evolutivos implementados para este trabajo, es necesario determinar los operadores de cruce y mutación, el método de selección de los cromosomas que van a cruzarse, el critero de selección de los cromosomas sobrevivientes y en caso del algoritmo memético el meme interno utilizado.

Para el caso del algoritmo genético generacional, el algoritmo genético estacionario y el algoritmo memético, se eligió como método se selección de cromosomas a cruzarse un proceso de torneo \cite{talbi2009metaheuristics}, el cual consiste en elegir k cromosomas de manera aleatoria y se eliminan k-1 donde el sobreviviente es el mejor dentro de los k. CHC por su parte elige dos cromosomas aleatorios y utiliza su mecanismo de prevención de incesto para elegir a los padres. 

El operador de cruce utilizado en GGA, SSGA y MA es la recombinación de un punto \cite{talbi2009metaheuristics}, el cual consiste en definir un punto u en el cual se va dividir los dos cromosomas seleccionados como padres $x_1$ y $x_2$, luego se forman dos hijos $y_1$ y $y_2$ donde la mitad de sus genes proviende de un padre y la otra mitad del otro padre. CHC en cambio usa el operador HUX explicado anteriormente. En la figura \ref{cruce} se muestra un ejemplo del cruce de un punto. 

\begin{figure}[]
\centering
\includegraphics[width=\textwidth]{cruce.png}
\caption[Cruce]{Cruce de un punto}
\label{cruce}
\end{figure}

El operador de mutación para GGA, SSGA y MA consta de cambiar 5\% de los genes del cromosoma de manera aleatoria. Se elige 5\%  basado en \cite{flores2014metaheuristics} para que la mutación represente un cambio real en el conjunto que representa el cromosoma, ya que si sólo se cambia un gen, el conjunto mutado sería para los efectos de la optimización casi idéntico al original. Sin embargo la probabilidad de que un cromosoma dado mute es baja, basado principalmente en los resultados de \emph{Cano, J.} en \cite{de2004reduccion} donde obtienen mejores resultados experimentales con bajas probabilidades de mutación (menor al 1\% por cromosoma), justificándose en que con mayores valores, la búsqueda podría degenerar en una búsqueda aleatoria. CHC por su parte no tiene mutación.

El criterio de reemplazo para GGA es generar una población nueva de hijos $P_i$ que va a suplantar la generación anterior $P_{i-1}$ excepto el mejor elemento en $P_{i-1}$, el cual toma el lugar del peor elemento de $P_i$ en la nueva generación. Por su parte, el criterio de selección de SSGA es que dado dos padres y los dos hijos producidos por el operador de cruce, se eligen los 2 mejores cromosomas para permanecer dentro de la población. MA, en cambio usa un criterio de selección en el cual los 2 hijos suplantan a los 2 peores elementos de la población y CHC se queda con los \texttt{n} mejores cromosomas entre $P_i$ y $P_{i-1}$, ambos casos son totalmente elitisitas.

El algoritmo memético es el que más adaptaciones tiene para adecuarse a PS, se usa una adaptación realizado por \emph{Cano, J. et al.} en \cite{garcia2008memetic}. Se basa en el algoritmo memético estacionario presentado anteriormente, con la peculariadad de que para decidir si los hijos producidos en una iteración van a ser optimizados con el meme, se usa un parámetro $P_{LS}$ que se determina de la siguiente forma:

\begin{equation}
P_{LS}=
\begin{cases}
1 & \text{si } \mathcal{F}(S_{nuevo}) < \mathcal{F}(S_{peor})\\
0.0625 & \text{en caso contrario}\\
\end{cases}
\end{equation}

Donde $\mathcal{F}$ es la función objetivo, $S_{nuevo}$ es el conjunto reducido representado por uno de los cromosomas hijos y $S_{peor}$ es el conjunto reducido representado por el peor cromosoma de la población. Es así como $P_{LS}$ representa la probabilidad con la cual se va a decidir si se optimiza el cromosoma hijo; $P_{LS}$ debe ser calculado para cada hijo creado en el cruce. La idea es que si el hijo es mejor que el peor cromosoma de la población, entonces vale la pena optimizarlo; en cambio, si es peor, se le da una probabilidad de 6,25\%.

El meme usado en MA es el que se presenta en \ref{meme}. El procedimiento consiste en ir reduciendo progesivamente las instancias que se encuentran en el conjunto S, representado por el cromosoma M, sin que se pierda la precisión asociada a S. Para esto, se usa una lista U del primer vecino más cercano de cada gen en M, una lista R que contien los genes que ya han sido puestos en 0 y que no generan una ganancia mayor al umbral de aceptación \texttt{t}, clase(i) es la clase asociada a la instancia representada por el gen i del cromosoma M, \texttt{ganancia} representa cuánto mejora (en caso de que sea positiva) o cuánto empeora (en caso de ser negativa) la solución dada por el cromosoma M luego de cambiar un gen, $fitness_M$ es el valor de evaluar la función objetivo con el cromosoma M y $fitness_{ganancia}$ se define como en la ecuación (2.4), donde L es el largo del cromosoma:

\begin{equation}
fitness_{ganancia} = \frac{\frac{ganancia}{L}*100 + \frac{100}{L}}{2}
\end{equation}  

El meme empieza a revisar los genes del cromosoma M que estén prendidos (con valor 1) y no se encuentren en la lista de revisados R en la línea 4; entonces, mientras se cumplan estas condiciones, se elige un $m_j$ que esté prendido y no esté en R, se apaga (coloca valor cero), se hace una copia de U a U', se actualiza la lista del primer vecino más cercano U tomando en cuenta que $m_j$ ya no pertenece al conjunto reducido S y por cada vecino de U que es actualizado, se actualiza la ganancia, sumando 1 si el gen i estaba mal clasificado anteriormente y con el nuevo vecino se clasifica correctamente (líneas 13 y 14) o restando 1 si el gen i estaba bien clasificado anteriormente y con el nuevo vecino se clasifica incorrectamente (líneas 11 y 12); acto seguido, se actualiza el \emph{fitness} del cromosoma M si la ganancia está por encima del umbral \texttt{t} y se limpia la lista de revisados R (líneas 15, 16 y 17) o en caso contrario, se recupera U con la copia U' y se prende de nuevo el gen $m_j$.  
 
\begin{algorithm}
\caption{Meme}
\label{meme}
\begin{algorithmic}[1]

\Require{\texttt{M} cromosoma a optimizar, \texttt{t} umbral de aceptación}
\Ensure{\texttt{M} cromosoma optimizado}

\State Sea $\texttt{M} = \left\{ m_1,m_2,\dots,m_n \right\}$ el cromosoma a optimizar 
\State $R \gets \emptyset$
\State $ U = \left\{ u_1,u_2,\dots,u_n \right\}$ la lista de vecinos asociados, donde $u_i$ es el vecino más cercano del gen i. 
\While{$(\exists m_i \in \texttt{M} \mid m_i = 1 \land i \notin R)$}
	\State elegir j aleatoriamente de \texttt{M} tal que $m_j=1 \land j \notin R$
	\State $ganancia \gets 0$
	\State $m_j \gets 0$
	\State Copiar U a U'
	\ForAll{$u_i \in U \mid u_i = j$}
		\State $u_i \gets$ nuevo vecino más cercano con el nuevo \texttt{M}
		\If{$clase(i) = clase(u'_i) \land clase(i) \neq clase(u_i)$}
			\State $ganancia \gets ganancia - 1$
		\ElsIf{$clase(i) \neq clase(u'_i) \land clase(i) = clase(u_i)$}
			\State $ganancia \gets ganancia + 1$
		\EndIf
	\EndFor
	\If{$ganancia \geq \texttt{t}$}
		\State \emph{$fitness_M$} $\gets$ \emph{$fitness_M$} + \emph{$fitness_{ganancia}$}
		\State $R \gets \emptyset$
	\Else
		\State Recuperar U de U'
		\State $m_j \gets 1$
		\State $ R \gets R \cup j$
	\EndIf
\EndWhile

\State \Return M

\end{algorithmic}
\end{algorithm}


\section{Conjunto de datos}

Los conjuntos de datos utilizados para validar el experimento provienen de \emph{UCI Machine Learning Repository} \cite{Dua:2017} y \emph{KEEL Data-Mining Software Tool} \cite{alcala2011keel}. Se hace una separación como la establecida en \cite{de2004reduccion} donde se considera como conjunto de datos pequeños aquellos con menos de 2000 instancias, los conuntos medianos los que poseen entre 2000 y 20000 instancias y los conjuntos grandes aquellos con más de 20000 instancias. En la tabla \ref{pequenios} se detallan los conjuntos pequeños, en \ref{medianos} los medianos y en \ref{grandes} los grandes. Solo se eligió conjunto de datos numéricos para poder utilizar la distancia euclideana para 1-NN sin problemas derivados de convertir datos categóricos.

\begin{table}[]
\centering
\begin{tabular}{l c c c}
\hline
\textsc{Conjunto} & \textsc{Instancias} & \textsc{Atributos} & \textsc{Clases} \\
\hline
\hline

Iris      & 150  &  4 &  3 \\
Cleveland & 297  & 13 &  5 \\
Led7Digit & 500  &  7 & 10 \\
Pima      & 768  &  8 &  2 \\
WDBC      & 569  & 30 &  2 \\
Monk-2    & 432  &  6 &  2 \\
Wisconsin & 683  &  9 &  2 \\
Wine      & 178  & 13 &  3 \\
Glass     & 214  &  9 &  7 \\
Banknote  & 1372 &  5 &  2 \\

\hline
\end{tabular}
\caption{Conjuntos de datos pequeños}
\label{pequenios}
\end{table}

\begin{table}[]
\centering
\begin{tabular}{l c c c}
\hline
\textsc{Conjunto} & \textsc{Instancias} & \textsc{Atributos} & \textsc{Clases} \\
\hline
\hline

Banana           &  5300 &  2 & 2 \\
Cardiotocography &  2126 & 23 & 3 \\
Eye-state        & 14980 & 15 & 2 \\
Page-blocks      &  5473 & 10 & 5 \\
Penbased         & 10992 & 16 & 10 \\
Satimage         &  6435 & 36 & 7 \\
Thyroid          &  7200 & 21 & 3 \\
Segment          &  2310 & 19 & 7 \\

\hline
\end{tabular}
\caption{Conjuntos de datos medianos}
\label{medianos}
\end{table}

\begin{table}[]
\centering
\begin{tabular}{l c c c}
\hline
\textsc{Conjunto} & \textsc{Instancias} & \textsc{Atributos} & \textsc{Clases} \\
\hline
\hline

Credit-card & 30000 & 24 & 2 \\
Shuttle     & 58000 & 9  & 7 \\

\hline
\end{tabular}
\caption{Conjuntos de datos grandes}
\label{grandes}
\end{table}

\section{Validación cruzada y estratificación}

Dado un conjunto de datos D, el proceso de validación cruzada \cite{kohavi1995study} consta de dividir D en k subconjuntos mutuamente exclusivos $D_1,D_2,\dots,D_k$ de aproximadamente el mismo tamaño, donde cada subconjunto mantiene la distribución de las clases como se encuentra en D. Luego se procede a probar el clasificador M, que en este caso es 1-NN, k veces, donde en cada prueba $t \in \left\{1,2,\dots,k\right\}$ se utiliza como conjunto de entrenamiento $TR=D \setminus D_t$, se aplica el algoritmo de selección de prototipos a TR y el conjunto resultante S se valida usando $TS=D_t$ como conjunto de prueba. El porcentaje de aciertos del clasificador se calcula como el promedio de las k pruebas realizadas; pero como las metaheurísticas tienen un componente estocástico, se necesita repetir cada prueba t varias veces. En este trabajo se decide por k = 10 y se repite cada prueba t 3 veces basándose en el trabajo de \emph{Cano, J.} en \cite{de2004reduccion}. Este esquema de validación cruzada es la forma clásica del método y se aplica a los conjuntos de tamaño pequeño como lo hacen en el trabajo antes citado. En la figura \ref{crossval} se muestra un esquema de cómo se aplica la validación cruzada para el problema de selección de instancias dado que la partición k es seleccionada como conjunto de prueba.

\begin{figure}[]
\centering
\includegraphics[scale=0.3]{classicCV.png}
\caption[Classic]{Validación cruzada clásica}
\label{crossval}
\end{figure}

Por otra parte está la estratificación, la cual es una técnica propuesta por \emph{Cano, J. et al.} en \cite{cano2005stratification} para solventar el problema de aplicación de los algoritmos de PS frente a conjunto de datos muy grandes. Dicho problema viene dado porque la mayoría de los algoritmos de PS y metaheurísticas utilizadas son $O(n^2)$, siendo n la cantidad de instancias del conjunto a procesar, y por lo tanto, para grandes volúmenes de datos estos algoritmos empiezan a tardar mucho en computar una solución, lo cual los vuelve poco útiles al momento de hacer preprocesamiento de datos. Es así que la estratificación se adopta como una técnica que lleva a tiempos aceptables el cómputo con conjuntos de muchas instancias. 

Dado un conjunto de datos D, la estratificación empieza dividiendo D en k subconjuntos, llamados estratos, mutuamente exclusivos $D_1,D_2,\dots,D_k$ de aproximadamente el mismo tamaño y preservando la distribución de clases presente en D. Luego, a diferencia de la validación cruzada clásica que forma un conjunto TR a partir de k-1 subconjuntos $D_i$, para luego aplicar el algoritmo de PS, en la estratificación se aplica el algoritmo de PS directamente a cada uno de los $k-1$ subconjuntos seleccionados para el entrenamiento, formando entonces subconjuntos reducidos $DS_1,DS_2,\dots,DS_{t-1},DS_{t+1},\dots,DS_k$, donde $D_t$ es el conjunto seleccionado como conjunto de prueba; acto seguido, se juntan todos los $DS_i$ para formar el conjunto reducido S que va a ser usado por 1-NN para clasificar $D_t$. La estratificación prueba ser un método efectivo, como lo demuestran en \cite{cano2005stratification}, ya que reduce considerablemente la cantidad de instancias que debe tratar el algoritmo de PS a $\frac{N}{k}$, por lo que la elección del número de estratos k se vuelve de especial importancia. Para este trabajo se adopta k = 10 para los conjuntos medianos y k = 50 para los conjuntos grandes, tal y como se determiann en \cite{cano2005stratification}, cuya idea es hacer que cada algoritmo de PS no trabaje con más de 2000 instancias por estrato para reducir la cantidad a un conjunto de tamaño pequeño según la clasificación anteriormente expuesta. Además, al igual que en la validación cruzada clásica, las metaheurísticas utilizadas son estocásticas y por lo tanto, cada una de las k pruebas realizadas se repite 3 veces, regresando el promedio de todas las pruebas realizadas como resultado. En la figura \ref{strat} se muestra un esquema de cómo se aplica la estratificación, donde el estrato k es seleccionado como conjunto de prueba.

\begin{figure}[]
\centering
\includegraphics[scale=0.3]{stratCV.png}
\caption[Classic]{Estratificación}
\label{strat}
\end{figure}

\section{Entonación de las metaheurísticas}

Para la entonación de las metaheurísticas se uso \emph{irace} \cite{lopez2016irace}, el cual es un paquete de R que implementa el método de entonación automática conocido como \emph{iterated F-race}, el cual forma parte de los métodos de filtro seǵún la taxonomía propuesta por \emph{Eiben, A. \& Smit, S.} en \cite{eiben2011parameter}. Como método de filtro, su principal objetivo es ir reduciendo los vectores de parámetros (configuraciones) a entonar paulatinamente, usando una competencia continua en la cual, cuando existen suficientes pruebas estadísticas de que una configuración genera una utilidad (evaluación de la función objetivo) con menos valor que el resto de las configuraciones, se elimina de las pruebas. Para mayor información respecto a la taxonomía de los métodos de entonación automática se recomienda leer \cite{eiben2011parameter}.


\emph{Iterated F-race} en específico trata de un método que consiste en tres pasos: (1) elegir varias configuraciones posibles de acuerdo a una distribución en particular y así formar una población, (2) elegir las mejores configuraciones de la poboblación por medio de un proceso de carrera y (3) actualizar la distribución de la población de tal manera que se sesgue a favor de las mejores configuraciones. Estos tres pasos son repetidos hasta que un criterio de parada es cumplido. El algoritmo de \emph{iterated F-race} se presenta en \ref{irace}.

\begin{algorithm}
\caption{IRACE}
\label{irace}
\begin{algorithmic}[1]

\Require{\texttt{I} conjunto de instancias del problema a entonar, \texttt{X} espacio de configuraciones, U función de utilidad, \texttt{B} presupuesto con el que se cuenta}
\Ensure{$\theta^{elite}$ mejores configuraciones encontradas}

\State $\theta_1 \gets$ una muestra uniforme de X
\State $\theta^{elite} \gets$ resultado de una \textbf{carrera} usando $\theta_1$ como población y con presupuesto $B_1$
\State $j \gets 1$
\While{$B^{usado} \leq B$}
	\State $j \gets j + 1$
	\State $\theta^{nueva} \gets$ muestra sesgada hacia $\theta^{elite}$ de X 
	\State $\theta_j \gets \theta^{nueva} \cup \theta^{elite}$
	\State $\theta^{elite} \gets$ resultado de una \textbf{carrera} usando $\theta_j$ como población y con presupuesto $B_j$
\EndWhile
\State \Return $\theta^{elite}$

\end{algorithmic}
\end{algorithm}

\emph{Irace} empieza estimando cuántas iteraciones $N^{iter}$ va a ejecutar; este valor está en función al número de parámetros que se piensa entonar, por lo tanto $N^{iter} = \lfloor 2 + log_2 N^{parámetros} \rfloor$, donde $N^{parámetros}$ representa el número de parámetros, con la idea de que mientras más parámetros se necesite entonar, mayor será la cantidad de iteraciones que una carrera en específico necesita para conseguir las configuraciones élites. El cálculo de cuántas carreras se van a realizar en total, calculado $N^{iter}$, va en función de cuanto presupuesto B se le asigne a todo el proceso; se calcula la cantidad de carrearas como $\lfloor B \backslash N^{iter} \rfloor$. Si la cantidad de carreras es 0 entonces \emph{irace} pide que se introduzca un B mayor. Para este estudio, se asignó $ B = 1000$ iteraciones.

Cabe acotar que \emph{irace} asume que el problema sobre el cual se va a entonar es un problema de minimización. Por lo tanto, siempre se busca menores valores de la función de utilidad U para cada configuración; además, luego de cada carrera asigna un rango $r_z$ dependiendo de cómo se compare la configuración z con respecto al resto, a menor rango, mejor es la configuración, por lo tanto, el conjunto de élites $\theta^{elite}$ está conformado por los k elementos con menor rango. El número k es calculado al principio de la corrida de \emph{irace} y en este trabajo se deja su cálculo automático por defecto.

Por otra parte,en la primera línea de \ref{irace}, se hace un muestreo uniforme del espacio de configuraciones X con una distribución normal truncada, en las siguientes iteraciones se va sesgando el muestreo con las configuraciones élites encontradas en la línea 6, esto se logra usando una probabilidad $p_z$ con la cual se toma una configuración $ \theta^z$ que se calcula como en la ecuación (2.5), donde $N^{elite}_{j-1}$ es el número de élites de la iteración j-1:

\begin{equation}
p_z = \frac{N^{elite}_{j-1} - r_z + 1}{N^{elite}_{j-1}*\frac{N^{elite}_{j-1}+1}{2}}
\end{equation} 

Una vez obtenido un $\theta^z$ se genera una nueva configuración tomando una muestra del espacio de parámetros X, un parámetro d a la vez de entre un rango $[d_{inf},d^{sup}]$ definido por el usuario, usando una distribución normal truncada $\mathcal{N}(\mu^z_d,(\sigma^j_d)^2)$ donde $\mu^z_d$, que representa la media, es el valor $\theta^z_d$ y la variancia $\sigma^j_d$ está definida como $(d^{sup}-d_{inf}) \backslash 2 $ en la iteración j, con una actualización progresiva  en cada iteración dada por la ecuación (2.6), donde $N^{nuevo}_j$ es el número de configuraciones en la población que se va a generar en la línea 6 de \ref{irace} en la iteración j, con el fin de acercar cada vez más los nuevos elemntos a la élite encontrada en las últimas iteraciones del experimento.

\begin{equation}
\sigma^j_d = \sigma^{j-1}_d *\left(\frac{1}{N^{nuevo}_j}\right)^{\frac{1}{N^{parámetros}}}
\end{equation}

El proceso de carrera (\emph{racing} en inglés) para la entonación de metaheurísticas con el cual se realiza el paso (2) (líneas 2 y 8), fue propuesto por \emph{Birattari, M. et al.} en \cite{birattari2002racing}. La carrera empieza usando una población con configuraciones; luego, a cada iteración de la carrera, las configuraciones son evaluadas en una sola instancia $I_j$. Después de un número iteraciones dadas por un parámetro T, aquellas configuraciones que estadísticamente tienen un desempeño inferior al resto son descartadas. \emph{Irace} establece  $T = 1$; además, puede una prueba Friedman no paramétrica o una prueba t-test como prueba estadística para hacer las comparaciones entre las configuraciones. Por recomendación de los autores, se usa una prueba t-test con un valor de significancia de 0.05 ya que, según sus criterios, es la más adecuada para la entonación de parámetros de valores continuos.

\emph{Irace}, además, implementa un método de reinicialización cuando la población de configuraciones converge prematuramente. En este proceso se mantienen las configuraciones élites de la última carrera y empieza de nuevo segun ciertas consideraciones. Aunado a esto, \emph{irace} también implementa un sistema de carrera elitista el cual evita que las mejores configuraciones encontradas hasta el momento se pierdan en una carrera producto de una serie desfavorable de evaluaciones en un momento dado. En este trabajo se usa ambas funciones como configuración por defecto que tiene \emph{irace}. Para más información de todas las funciones y utilidades que presenta esta herramemienta, se recomienda leer \cite{lopez2016irace}.

\section{Diseño experimental}